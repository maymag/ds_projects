{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.types import DoubleType\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.feature import IndexToString, StringIndexer, VectorIndexer, VectorAssembler\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "from pyspark.sql.functions import isnan, when, count, col\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyspark.sql.functions import UserDefinedFunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_NAME = \"/home/ds/notebooks/datasets/amazonreviews/AmznInstantVideo.json\"\n",
    "APP_NAME = \"Amazon Video Reviews\"\n",
    "SPARK_URL = \"local[*]\"\n",
    "RANDOM_SEED = 141107\n",
    "TRAINING_DATA_RATIO = 0.8\n",
    "RF_NUM_TREES = 10\n",
    "RF_MAX_DEPTH = 4\n",
    "RF_NUM_BINS = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(APP_NAME).master(SPARK_URL).getOrCreate()\n",
    "sqlContext = SQLContext(spark)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sqlContext.read.json(DATA_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns:\n",
      "9\n",
      "Rows:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "37121"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check shape of data\n",
    "print('Columns:')\n",
    "print(len(df.columns))\n",
    "print('Rows:')\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- asin: string (nullable = true)\n",
      " |-- helpful: array (nullable = true)\n",
      " |    |-- element: long (containsNull = true)\n",
      " |-- overall: double (nullable = true)\n",
      " |-- reviewText: string (nullable = true)\n",
      " |-- reviewTime: string (nullable = true)\n",
      " |-- reviewerID: string (nullable = true)\n",
      " |-- reviewerName: string (nullable = true)\n",
      " |-- summary: string (nullable = true)\n",
      " |-- unixReviewTime: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|          reviewText|             summary|\n",
      "+--------------------+--------------------+\n",
      "|I had big expecta...|A little bit bori...|\n",
      "|I highly recommen...|Excellent Grown U...|\n",
      "|This one is a rea...|Way too boring fo...|\n",
      "|Mysteries are int...|Robson Green is m...|\n",
      "|This show always ...|Robson green and ...|\n",
      "|I discovered this...|I purchased the s...|\n",
      "|It beats watching...|It takes up your ...|\n",
      "|There are many ep...|A reasonable way ...|\n",
      "|This is the best ...|           kansas001|\n",
      "|Not bad.  Didn't ...| Entertaining Comedy|\n",
      "|Funny, interestin...|     Worth watching!|\n",
      "|I love the variet...|comedy club quali...|\n",
      "|comedy is a matte...|                  ok|\n",
      "|if this had to do...|not sure who this...|\n",
      "|Watched it for Ke...|           Loved it!|\n",
      "|he's OK. His humo...|same routine he d...|\n",
      "|some comedians ar...|           it was ok|\n",
      "|I only watched th...|I Only Watched Wa...|\n",
      "|Enjoyed some of t...|     Some were funny|\n",
      "|All the comedians...|              kansas|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"reviewText\", \"summary\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.registerTempTable('reviews')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+\n",
      "|overall|reviewCount|\n",
      "+-------+-----------+\n",
      "|    5.0|      20888|\n",
      "|    4.0|       8445|\n",
      "|    3.0|       4185|\n",
      "|    2.0|       1885|\n",
      "|    1.0|       1718|\n",
      "+-------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Look at review stars coding\n",
    "sqlContext.sql(\"select overall, count(overall) as reviewCount from reviews group by overall order by overall desc\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns:\n",
      "9\n",
      "Rows:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "37121"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Columns:')\n",
    "print(len(df.columns))\n",
    "print('Rows:')\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create function to make over 3 stars positive\n",
    "udf = UserDefinedFunction (lambda x: 1 if x > 3 else 0, IntegerType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new dataframe with binary coding for pos/neg opinions\n",
    "df2 = df.withColumn(\"recode\",udf(df.overall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|recode|             feature|\n",
      "+------+--------------------+\n",
      "|     0|(20,[0,1,3,5,6,7,...|\n",
      "|     1|(20,[1,2,3,4,5,8,...|\n",
      "|     0|(20,[0,1,4,5,6,7,...|\n",
      "|     1|(20,[0,1,2,3,8,9,...|\n",
      "|     1|(20,[0,1,2,3,4,5,...|\n",
      "|     1|(20,[0,1,2,3,4,5,...|\n",
      "|     0|(20,[0,3,5,6,7,8,...|\n",
      "|     0|(20,[1,3,4,5,6,7,...|\n",
      "|     1|(20,[0,1,2,3,4,5,...|\n",
      "|     0|(20,[0,2,3,7,8,10...|\n",
      "|     1|(20,[0,1,8,9,10,1...|\n",
      "|     1|(20,[0,1,2,3,5,6,...|\n",
      "|     0|(20,[0,1,3,7,10,1...|\n",
      "|     0|(20,[0,1,2,3,5,7,...|\n",
      "|     1|(20,[0,1,2,3,6,9,...|\n",
      "|     0|(20,[0,1,2,3,5,9,...|\n",
      "|     0|(20,[0,1,2,3,4,5,...|\n",
      "|     0|(20,[0,1,2,3,4,5,...|\n",
      "|     1|(20,[0,3,5,8,9,10...|\n",
      "|     1|(20,[0,1,2,3,4,5,...|\n",
      "+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Tokenize and vectorize reviewText column using tf-idf\n",
    "from pyspark.ml.feature import Tokenizer\n",
    "tokenizer = Tokenizer(inputCol=\"reviewText\", outputCol=\"tokenized_text\").transform(df2)\n",
    "from pyspark.ml.feature import HashingTF, IDF\n",
    "hashingTF = HashingTF(inputCol=\"tokenized_text\", outputCol=\"rawFeatures\", numFeatures=20)\n",
    "featurizedData = hashingTF.transform(tokenizer)\n",
    "\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"feature\")\n",
    "idfModel = idf.fit(featurizedData)\n",
    "rescaledData = idfModel.transform(featurizedData)\n",
    "\n",
    "rescaledData.select(\"recode\", \"feature\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+--------------------+\n",
      "|recode|             feature|            feature2|\n",
      "+------+--------------------+--------------------+\n",
      "|     0|(20,[0,1,3,5,6,7,...|(20,[4,6,10,11,16...|\n",
      "|     1|(20,[1,2,3,4,5,8,...|(20,[1,6,8,10],[1...|\n",
      "|     0|(20,[0,1,4,5,6,7,...|(20,[4,11,16,19],...|\n",
      "|     1|(20,[0,1,2,3,8,9,...|(20,[1,5,15,18],[...|\n",
      "|     1|(20,[0,1,2,3,4,5,...|(20,[0,5,13,17,18...|\n",
      "|     1|(20,[0,1,2,3,4,5,...|(20,[3,8,9,10,11,...|\n",
      "|     0|(20,[0,3,5,6,7,8,...|(20,[3,8,14,15],[...|\n",
      "|     0|(20,[1,3,4,5,6,7,...|(20,[0,6,8,10,15,...|\n",
      "|     1|(20,[0,1,2,3,4,5,...|(20,[3],[1.444927...|\n",
      "|     0|(20,[0,2,3,7,8,10...|(20,[13,19],[1.39...|\n",
      "|     1|(20,[0,1,8,9,10,1...|(20,[3,12],[1.444...|\n",
      "|     1|(20,[0,1,2,3,5,6,...|(20,[3,4,5,7,13,1...|\n",
      "|     0|(20,[0,1,3,7,10,1...|(20,[4],[1.778752...|\n",
      "|     0|(20,[0,1,2,3,5,7,...|(20,[1,13,14,16,1...|\n",
      "|     1|(20,[0,1,2,3,6,9,...|(20,[11,17],[1.75...|\n",
      "|     0|(20,[0,1,2,3,5,9,...|(20,[2,3,6,7,9,16...|\n",
      "|     0|(20,[0,1,2,3,4,5,...|(20,[4,14,15],[1....|\n",
      "|     0|(20,[0,1,2,3,4,5,...|(20,[8,9,11,19],[...|\n",
      "|     1|(20,[0,3,5,8,9,10...|(20,[0,2,7],[1.30...|\n",
      "|     1|(20,[0,1,2,3,4,5,...|(20,[9],[1.732304...|\n",
      "+------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Tokenize and vectorize summary column using tf-idf\n",
    "tokenizer = Tokenizer(inputCol=\"summary\", outputCol=\"tokenized_text2\").transform(rescaledData)\n",
    "hashingTF = HashingTF(inputCol=\"tokenized_text2\", outputCol=\"rawFeatures2\", numFeatures=20)\n",
    "featurizedData = hashingTF.transform(tokenizer)\n",
    "\n",
    "idf = IDF(inputCol=\"rawFeatures2\", outputCol=\"feature2\")\n",
    "idfModel = idf.fit(featurizedData)\n",
    "rescaledData2 = idfModel.transform(featurizedData)\n",
    "\n",
    "rescaledData2.select(\"recode\", \"feature\",\"feature2\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Put review text and summary vectors into one vector\n",
    "df3 = VectorAssembler(inputCols=['feature','feature2'], outputCol=\"features\").transform(rescaledData2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|recode|            features|\n",
      "+------+--------------------+\n",
      "|     0|(40,[0,1,3,5,6,7,...|\n",
      "|     1|(40,[1,2,3,4,5,8,...|\n",
      "|     0|(40,[0,1,4,5,6,7,...|\n",
      "|     1|(40,[0,1,2,3,8,9,...|\n",
      "|     1|(40,[0,1,2,3,4,5,...|\n",
      "|     1|[2.28483993183917...|\n",
      "|     0|(40,[0,3,5,6,7,8,...|\n",
      "|     0|(40,[1,3,4,5,6,7,...|\n",
      "|     1|(40,[0,1,2,3,4,5,...|\n",
      "|     0|(40,[0,2,3,7,8,10...|\n",
      "|     1|(40,[0,1,8,9,10,1...|\n",
      "|     1|(40,[0,1,2,3,5,6,...|\n",
      "|     0|(40,[0,1,3,7,10,1...|\n",
      "|     0|(40,[0,1,2,3,5,7,...|\n",
      "|     1|(40,[0,1,2,3,6,9,...|\n",
      "|     0|(40,[0,1,2,3,5,9,...|\n",
      "|     0|(40,[0,1,2,3,4,5,...|\n",
      "|     0|(40,[0,1,2,3,4,5,...|\n",
      "|     1|(40,[0,3,5,8,9,10...|\n",
      "|     1|(40,[0,1,2,3,4,5,...|\n",
      "+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3.select(\"recode\", \"features\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the training indexers, split data (set aside 30% for testing)\n",
    "\n",
    "labelIndexer = StringIndexer(inputCol=\"recode\", outputCol=\"indexedLabel\").fit(df3)\n",
    "\n",
    "featureIndexer = VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=4).fit(df3)\n",
    "    \n",
    "(trainingData, testData) = df3.randomSplit([TRAINING_DATA_RATIO, 1 - TRAINING_DATA_RATIO])\n",
    "\n",
    "# Train a RandomForest model.\n",
    "rf = RandomForestClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\", numTrees=RF_NUM_TREES)\n",
    "\n",
    "# Make pipeline of indexers and RFC\n",
    "pipeline = Pipeline(stages=[labelIndexer, featureIndexer, rf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model  \n",
    "model = pipeline.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "predictions = model.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error:\n",
      "0.20203548342731403\n",
      "Accuracy:\n",
      "0.797964516572686\n"
     ]
    }
   ],
   "source": [
    "# test error\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "\n",
    "print(\"Test Error:\")\n",
    "print(1-accuracy)\n",
    "print(\"Accuracy:\")\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
